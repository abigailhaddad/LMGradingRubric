{
  "version": 1,
  "status": "error",
  "eval": {
    "task": "my_eval",
    "task_version": 0,
    "task_id": "XVfXY7VKMVmMaFpMFYLZTF",
    "run_id": "hWio7cxpazWdobiXpvMsPd",
    "created": "2024-05-23T17:09:51",
    "dataset": {},
    "model": "openai/gpt-4o",
    "task_attribs": {},
    "task_args": {},
    "model_args": {},
    "config": {},
    "revision": {
      "type": "git",
      "origin": "https://github.com/abigailhaddad/LMGradingRubric.git",
      "commit": "69149b9"
    },
    "packages": {
      "inspect_ai": "0.3.4.dev1+g6cfb4fe"
    }
  },
  "plan": {
    "name": "plan",
    "steps": [
      {
        "solver": "system_message",
        "params": {
          "message": "You are an AI assistant helping with fact comparison."
        }
      },
      {
        "solver": "generate",
        "params": {}
      }
    ],
    "config": {}
  },
  "stats": {
    "started_at": "2024-05-23T17:09:51",
    "completed_at": "2024-05-23T17:09:57",
    "model_usage": {
      "openai/gpt-4o": {
        "input_tokens": 776,
        "output_tokens": 183,
        "total_tokens": 959
      }
    }
  },
  "error": {
    "message": "TypeError(\"string indices must be integers, not 'str'\")",
    "traceback": "Traceback (most recent call last):\n\n  File \"C:\\Users\\abiga\\OneDrive\\Documents\\PythonScripts\\LLMGradingRubric\\env\\Lib\\site-packages\\inspect_ai\\_eval\\task.py\", line 296, in run\n    scores = await asyncio.gather(*tasks)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\abiga\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n    future.result()\n\n  File \"C:\\Users\\abiga\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 267, in __step\n    result = coro.send(None)\n             ^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\abiga\\OneDrive\\Documents\\PythonScripts\\LLMGradingRubric\\env\\Lib\\site-packages\\inspect_ai\\_eval\\task.py\", line 428, in run_eval_task\n    result = await scorer(state, Target(sample.target)) if scorer else None\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\abiga\\AppData\\Local\\Temp\\ipykernel_31552\\876705201.py\", line 64, in score\n    explanation = score.explanation['comparison_result'].facts_in_both\n                  ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n\nTypeError: string indices must be integers, not 'str'\n",
    "traceback_ansi": "\u001b[31m+-\u001b[0m\u001b[31m------------------------------\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m-------------------------------\u001b[0m\u001b[31m-+\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33mC:\\Users\\abiga\\OneDrive\\Documents\\PythonScripts\\LLMGradingRubric\\env\\Lib\\site-packages\\inspect_a\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33mi\\_eval\\task.py\u001b[0m:\u001b[94m296\u001b[0m in \u001b[92mrun\u001b[0m                                                                       \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m                                                                                                  \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33mC:\\Users\\abiga\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\u001b[0m:\u001b[94m339\u001b[0m in \u001b[92m__wakeup\u001b[0m      \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m                                                                                                  \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33mC:\\Users\\abiga\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\u001b[0m:\u001b[94m267\u001b[0m in \u001b[92m__step\u001b[0m        \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m                                                                                                  \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33mC:\\Users\\abiga\\OneDrive\\Documents\\PythonScripts\\LLMGradingRubric\\env\\Lib\\site-packages\\inspect_a\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33mi\\_eval\\task.py\u001b[0m:\u001b[94m428\u001b[0m in \u001b[92mrun_eval_task\u001b[0m                                                             \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m                                                                                                  \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m in \u001b[92mscore\u001b[0m:\u001b[94m64\u001b[0m                                                                                      \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m                                                                                                  \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m   \u001b[2m 61 \u001b[0m    \u001b[2m# Ignore the actual processing and return a dummy value\u001b[0m                                \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m   \u001b[2m 62 \u001b[0m    grounded_score = score.value[\u001b[33m'\u001b[0m\u001b[33mgroundedness\u001b[0m\u001b[33m'\u001b[0m]                                           \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m   \u001b[2m 63 \u001b[0m    thorough_score = score.value[\u001b[33m'\u001b[0m\u001b[33mthoroughness\u001b[0m\u001b[33m'\u001b[0m]                                           \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[31m‚ù± \u001b[0m 64     explanation = score.explanation[\u001b[33m'\u001b[0m\u001b[33mcomparison_result\u001b[0m\u001b[33m'\u001b[0m].facts_in_both                     \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m   \u001b[2m 65 \u001b[0m                                                                                           \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m   \u001b[2m 66 \u001b[0m    answer = state.output.completion                                                       \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m   \u001b[2m 67 \u001b[0m                                                                                           \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m                                                                                                  \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m+-\u001b[0m\u001b[33m------------------------------------------\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m------------------------------------------\u001b[0m\u001b[33m-+\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m fact_comparator_scorer = \u001b[1m<\u001b[0m\u001b[1;95m__main__.FactComparatorScorer\u001b[0m\u001b[39m object at \u001b[0m\u001b[94m0x0000020DE83E6710\u001b[0m\u001b[1m>\u001b[0m        \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m         grounded_score = \u001b[94m50.0\u001b[0m                                                                \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                  model = \u001b[1;35mInspectChatModel\u001b[0m\u001b[1m(\u001b[0m                                                   \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                              \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m                                                      \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                  \u001b[1;35mChatMessageUser\u001b[0m\u001b[1m(\u001b[0m                                            \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                      \u001b[33mcontent\u001b[0m=\u001b[33m'\\n            You will be comparing facts \u001b[0m     \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                          \u001b[33mbetween a context and an answer to dete'\u001b[0m+\u001b[94m1735\u001b[0m,                      \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                      \u001b[33msource\u001b[0m=\u001b[94mNone\u001b[0m,                                            \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                      \u001b[33mrole\u001b[0m=\u001b[33m'user'\u001b[0m                                             \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                  \u001b[1m)\u001b[0m,                                                          \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                  \u001b[1;35mChatMessageAssistant\u001b[0m\u001b[1m(\u001b[0m                                       \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                      \u001b[33mcontent\u001b[0m=\u001b[33m'\u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m\\n    \"facts_in_both\": \u001b[0m\u001b[1;33m[\u001b[0m\u001b[33m\\n        \"The fox is\u001b[0m \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                          \u001b[33mbrown.\"\\n    \u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m,\\n    \"facts_only_in_a'\u001b[0m+\u001b[94m110\u001b[0m,                         \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                      \u001b[33msource\u001b[0m=\u001b[33m'generate'\u001b[0m,                                      \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                      \u001b[33mrole\u001b[0m=\u001b[33m'assistant'\u001b[0m,                                       \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                      \u001b[33mtool_calls\u001b[0m=\u001b[94mNone\u001b[0m                                         \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                  \u001b[1m)\u001b[0m                                                           \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                              \u001b[1m]\u001b[0m,                                                              \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                              \u001b[33moutput\u001b[0m=\u001b[1;35mModelOutput\u001b[0m\u001b[1m(\u001b[0m                                             \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                  \u001b[33mmodel\u001b[0m=\u001b[33m'gpt-4o-2024-05-13'\u001b[0m,                                  \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                  \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m                                                   \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                      \u001b[1;35mChatCompletionChoice\u001b[0m\u001b[1m(\u001b[0m                                   \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                          \u001b[33mmessage\u001b[0m=\u001b[1;35mChatMessageAssistant\u001b[0m\u001b[1m(\u001b[0m                       \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                              \u001b[33mcontent\u001b[0m=\u001b[33m'\u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m\\n    \"facts_in_both\": \u001b[0m\u001b[1;33m[\u001b[0m\u001b[33m\\n        \u001b[0m    \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                          \u001b[33m\"The fox is brown.\"\\n    \u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m,\\n    \"facts_only_in_a'\u001b[0m+\u001b[94m110\u001b[0m,             \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                              \u001b[33msource\u001b[0m=\u001b[33m'generate'\u001b[0m,                              \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                              \u001b[33mrole\u001b[0m=\u001b[33m'assistant'\u001b[0m,                               \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                              \u001b[33mtool_calls\u001b[0m=\u001b[94mNone\u001b[0m                                 \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                          \u001b[1m)\u001b[0m,                                                  \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                          \u001b[33mstop_reason\u001b[0m=\u001b[33m'stop'\u001b[0m,                                 \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                          \u001b[33mlogprobs\u001b[0m=\u001b[94mNone\u001b[0m                                       \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                      \u001b[1m)\u001b[0m                                                       \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                  \u001b[1m]\u001b[0m,                                                          \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                  \u001b[33musage\u001b[0m=\u001b[1;35mModelUsage\u001b[0m\u001b[1m(\u001b[0m                                           \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                      \u001b[33minput_tokens\u001b[0m=\u001b[94m371\u001b[0m,                                       \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                      \u001b[33moutput_tokens\u001b[0m=\u001b[94m53\u001b[0m,                                       \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                      \u001b[33mtotal_tokens\u001b[0m=\u001b[94m424\u001b[0m                                        \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                  \u001b[1m)\u001b[0m,                                                          \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                                  \u001b[33merror\u001b[0m=\u001b[94mNone\u001b[0m                                                  \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                              \u001b[1m)\u001b[0m                                                               \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                          \u001b[1m)\u001b[0m                                                                   \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                  score = \u001b[1;35mScore\u001b[0m\u001b[1m(\u001b[0m                                                              \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                              \u001b[33mvalue\u001b[0m=\u001b[1m{\u001b[0m\u001b[33m'groundedness'\u001b[0m: \u001b[94m50.0\u001b[0m, \u001b[33m'thoroughness'\u001b[0m: \u001b[94m50.0\u001b[0m\u001b[1m}\u001b[0m,             \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                              \u001b[33manswer\u001b[0m=\u001b[94mNone\u001b[0m,                                                    \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                              \u001b[33mexplanation\u001b[0m=\u001b[33m\"\u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m'context_list': '\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;33mfacts\u001b[0m\u001b[33m>\\\\nThe fox is \u001b[0m            \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                          \u001b[33mbrown.\\\\nThe dog is white.\\\\n</facts\u001b[0m\u001b[1;33m>\u001b[0m\u001b[33m', 'ans\"\u001b[0m+\u001b[94m288\u001b[0m,                  \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                              \u001b[33mmetadata\u001b[0m=\u001b[94mNone\u001b[0m                                                   \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                          \u001b[1m)\u001b[0m                                                                   \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                  state = \u001b[1m<\u001b[0m\u001b[1;95minspect_ai.solver._solver.TaskState\u001b[0m\u001b[39m object at \u001b[0m\u001b[94m0x0000020DE84DE0D0\u001b[0m\u001b[1m>\u001b[0m  \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m                 target = \u001b[1m<\u001b[0m\u001b[1;95minspect_ai.scorer._scorer.Target\u001b[0m\u001b[39m object at \u001b[0m\u001b[94m0x0000020DE8823F50\u001b[0m\u001b[1m>\u001b[0m     \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m|\u001b[0m         thorough_score = \u001b[94m50.0\u001b[0m                                                                \u001b[33m|\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m|\u001b[0m \u001b[33m+----------------------------------------------------------------------------------------------+\u001b[0m \u001b[31m|\u001b[0m\n\u001b[31m+--------------------------------------------------------------------------------------------------+\u001b[0m\n\u001b[1;91mTypeError: \u001b[0mstring indices must be integers, not \u001b[32m'str'\u001b[0m\n"
  },
  "logging": []
}